{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Iniciando an√°lisis de TED Talks\n",
            "üìä Dataset: ted_talks_en.csv\n",
            "üéØ Objetivo: Extracci√≥n de informaci√≥n + Modelos ML\n",
            "üìä Cargando m√≥dulos del proyecto TED Talks...\n",
            "‚úì M√≥dulo de configuraci√≥n del ambiente cargado\n",
            "‚úì M√≥dulo de limpieza de datos cargado\n",
            "‚úì M√≥dulo de procesamiento NLP cargado\n",
            "‚úì M√≥dulo de visualizaci√≥n cargado\n",
            "‚úì M√≥dulo de machine learning cargado\n",
            "üéØ M√≥dulos TED Talks cargados correctamente\n",
            "üìö Uso recomendado:\n",
            "   from modules import quick_start\n",
            "   analyzer, results = quick_start('ted_talks_en.csv')\n",
            "==================================================\n",
            "‚úÖ M√≥dulos cargados correctamente\n"
          ]
        }
      ],
      "source": [
        "# === PROYECTO DE AN√ÅLISIS DE POPULARIDAD DE TED TALKS ===\n",
        "# Aplicaci√≥n de Extracci√≥n de Informaci√≥n y Comparaci√≥n de Modelos ML\n",
        "\n",
        "print(\"üöÄ Iniciando an√°lisis de TED Talks\")\n",
        "print(\"üìä Dataset: ted_talks_en.csv\")\n",
        "print(\"üéØ Objetivo: Extracci√≥n de informaci√≥n + Modelos ML\")\n",
        "\n",
        "# Importar m√≥dulos del proyecto\n",
        "from modules import TedTalkAnalyzer\n",
        "from modules.environment_setup import setup_environment\n",
        "from modules.data_cleaner import clean_dataset_professional\n",
        "from modules.nlp_processor import process_text_features\n",
        "from modules.ml_models import create_ml_pipeline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ M√≥dulos cargados correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === CONFIGURACI√ìN DEL AMBIENTE ===\n",
        "\n",
        "print(\"\udd27 Configurando ambiente y dependencias...\")\n",
        "\n",
        "# Configurar ambiente autom√°ticamente\n",
        "setup_environment()\n",
        "\n",
        "print(\"‚úÖ Ambiente configurado correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === CARGA Y LIMPIEZA DE DATOS ===\n",
        "\n",
        "print(\"\udcc2 Cargando dataset ted_talks_en.csv...\")\n",
        "\n",
        "# Cargar dataset\n",
        "df_original = pd.read_csv('ted_talks_en.csv')\n",
        "print(f\"Dataset original: {df_original.shape[0]} filas x {df_original.shape[1]} columnas\")\n",
        "\n",
        "# Limpieza profesional de datos (eliminar outliers, crear categor√≠as)\n",
        "print(\"\\nüßπ Aplicando limpieza profesional...\")\n",
        "df_clean, cleaning_log = clean_dataset_professional(df_original)\n",
        "\n",
        "print(f\"Dataset limpio: {df_clean.shape[0]} filas x {df_clean.shape[1]} columnas\")\n",
        "print(f\"Filas eliminadas: {df_original.shape[0] - df_clean.shape[0]}\")\n",
        "\n",
        "# Mostrar categor√≠as de popularidad creadas\n",
        "print(\"\\nCategor√≠as de popularidad:\")\n",
        "print(df_clean['popularity_category'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === EXTRACCI√ìN DE INFORMACI√ìN CON NLP ===\n",
        "\n",
        "print(\"üî§ Aplicando t√©cnicas de extracci√≥n de informaci√≥n...\")\n",
        "print(\"üìä Procesando: sentimientos, entidades nombradas, caracter√≠sticas textuales\")\n",
        "\n",
        "# Procesar caracter√≠sticas NLP en una muestra para velocidad\n",
        "sample_size = min(200, len(df_clean))\n",
        "df_sample = df_clean.head(sample_size).copy()\n",
        "\n",
        "print(f\"Procesando muestra de {sample_size} registros para extracci√≥n de informaci√≥n...\")\n",
        "\n",
        "# Aplicar procesamiento NLP completo\n",
        "df_with_nlp = process_text_features(df_sample, text_column='transcript_clean')\n",
        "\n",
        "# Mostrar caracter√≠sticas extra√≠das\n",
        "nlp_features = [col for col in df_with_nlp.columns if \n",
        "               col.startswith(('sentiment_', 'text_', 'person_', 'org_', 'gpe_'))]\n",
        "\n",
        "print(f\"\\n‚úÖ Caracter√≠sticas NLP extra√≠das: {len(nlp_features)}\")\n",
        "print(\"Tipos de informaci√≥n extra√≠da:\")\n",
        "for feature in nlp_features[:10]:  # Mostrar solo primeras 10\n",
        "    print(f\"  - {feature}\")\n",
        "\n",
        "if len(nlp_features) > 10:\n",
        "    print(f\"  ... y {len(nlp_features) - 10} m√°s\")\n",
        "\n",
        "print(f\"\\nDataset con informaci√≥n extra√≠da: {df_with_nlp.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-03T07:03:25.803244Z",
          "start_time": "2025-08-03T07:03:25.143615Z"
        },
        "cell_id": "5abe3fcf07e4410ea49ff1de3fca1b50",
        "deepnote_cell_type": "code",
        "execution_context_id": "d6f386e3-c5a2-41fb-85f0-dac17a4ccd4f",
        "execution_millis": 95512,
        "execution_start": 1754262986754,
        "source_hash": "ecbd79b7"
      },
      "outputs": [],
      "source": [
        "# === ENTRENAMIENTO Y COMPARACI√ìN DE MODELOS ML ===\n",
        "\n",
        "print(\"ü§ñ Entrenando y comparando modelos de Machine Learning...\")\n",
        "print(\"üéØ Objetivo: F1-score > 0.78\")\n",
        "\n",
        "# Crear pipeline completo de ML usando los datos procesados\n",
        "classifier, ml_results = create_ml_pipeline(\n",
        "    df_with_nlp, \n",
        "    text_column='transcript_clean',\n",
        "    target_column='popularity_numeric'\n",
        ")\n",
        "\n",
        "print(\"\\nüìä RESULTADOS DE MODELOS:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Mostrar resultados de cada modelo\n",
        "for model_name, results in ml_results.items():\n",
        "    if results is not None:\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(f\"  Accuracy:  {results['accuracy']:.4f}\")\n",
        "        print(f\"  Precision: {results['precision']:.4f}\")\n",
        "        print(f\"  Recall:    {results['recall']:.4f}\")\n",
        "        print(f\"  F1-Score:  {results['f1_score']:.4f}\")\n",
        "        \n",
        "        # Verificar si cumple objetivo\n",
        "        objetivo_cumplido = \"‚úÖ\" if results['f1_score'] > 0.78 else \"‚ùå\"\n",
        "        print(f\"  Objetivo F1>0.78: {objetivo_cumplido}\")\n",
        "\n",
        "# Identificar mejor modelo\n",
        "best_model_name, best_model, best_score = classifier.get_best_model()\n",
        "print(f\"\\nüèÜ MEJOR MODELO: {best_model_name}\")\n",
        "print(f\"üìà F1-Score: {best_score:.4f}\")\n",
        "\n",
        "if best_score > 0.78:\n",
        "    print(\"üéâ ¬°Objetivo cumplido! F1-Score > 0.78\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Objetivo no cumplido. Considerar m√°s datos o mejores caracter√≠sticas.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-02T20:23:05.092879Z",
          "start_time": "2025-08-02T20:23:05.090755Z"
        },
        "cell_id": "e311e55f07eb4774aef2d27d4ba3f105",
        "deepnote_cell_type": "code",
        "execution_context_id": "d6f386e3-c5a2-41fb-85f0-dac17a4ccd4f",
        "execution_millis": 5768,
        "execution_start": 1754263082313,
        "source_hash": "f325302b"
      },
      "outputs": [],
      "source": [
        "# === M√âTRICAS DE RENDIMIENTO Y VISUALIZACIONES ===\n",
        "\n",
        "print(\"üìä Generando m√©tricas de rendimiento y visualizaciones...\")\n",
        "\n",
        "# Mostrar importancia de caracter√≠sticas del mejor modelo\n",
        "feature_importance = classifier.get_feature_importance(best_model_name, top_n=15)\n",
        "\n",
        "# Crear visualizaciones de evaluaci√≥n (matrices de confusi√≥n, comparaci√≥n de m√©tricas)\n",
        "y_test = None  # Se obtiene internamente del clasificador\n",
        "classifier.create_evaluation_plots(y_test)\n",
        "\n",
        "# Visualizaciones de datos usando el m√≥dulo visualizer\n",
        "from modules.visualizer import create_data_overview_plots, print_summary_statistics\n",
        "\n",
        "print(\"\\nüìà Estad√≠sticas del dataset procesado:\")\n",
        "print_summary_statistics(df_with_nlp)\n",
        "\n",
        "print(\"\\nüìä Creando visualizaciones de resumen...\")\n",
        "create_data_overview_plots(df_with_nlp)\n",
        "\n",
        "print(\"‚úÖ An√°lisis completo finalizado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "ba14dbd4adcd427685627c07bc45b6ec",
        "deepnote_cell_type": "code",
        "execution_context_id": "d6f386e3-c5a2-41fb-85f0-dac17a4ccd4f",
        "execution_millis": 578,
        "execution_start": 1754263088133,
        "source_hash": "8f5ea635"
      },
      "outputs": [],
      "source": [
        "# === CONCLUSIONES Y RECOMENDACIONES ===\n",
        "\n",
        "print(\"üìã CONCLUSIONES DEL AN√ÅLISIS:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Resumen de datos procesados\n",
        "original_count = df_original.shape[0]\n",
        "clean_count = df_clean.shape[0]\n",
        "outliers_removed = original_count - clean_count\n",
        "\n",
        "print(f\"üìä Datos procesados:\")\n",
        "print(f\"  - Registros originales: {original_count:,}\")\n",
        "print(f\"  - Registros despu√©s de limpieza: {clean_count:,}\")\n",
        "print(f\"  - Outliers eliminados: {outliers_removed:,} ({outliers_removed/original_count*100:.1f}%)\")\n",
        "\n",
        "# Resumen de extracci√≥n de informaci√≥n\n",
        "nlp_features_count = len([col for col in df_with_nlp.columns if \n",
        "                         col.startswith(('sentiment_', 'text_', 'person_', 'org_'))])\n",
        "\n",
        "print(f\"\\nüî§ Extracci√≥n de informaci√≥n:\")\n",
        "print(f\"  - Caracter√≠sticas NLP extra√≠das: {nlp_features_count}\")\n",
        "print(f\"  - T√©cnicas aplicadas: An√°lisis de sentimientos, NER, caracter√≠sticas textuales\")\n",
        "\n",
        "# Resumen de modelos\n",
        "models_trained = len([r for r in ml_results.values() if r is not None])\n",
        "models_above_threshold = len([r for r in ml_results.values() \n",
        "                             if r is not None and r['f1_score'] > 0.78])\n",
        "\n",
        "print(f\"\\nü§ñ Modelos de Machine Learning:\")\n",
        "print(f\"  - Modelos entrenados: {models_trained}\")\n",
        "print(f\"  - Modelos con F1 > 0.78: {models_above_threshold}\")\n",
        "print(f\"  - Mejor modelo: {best_model_name} (F1: {best_score:.4f})\")\n",
        "\n",
        "# Recomendaciones\n",
        "print(f\"\\nüí° RECOMENDACIONES:\")\n",
        "if best_score > 0.78:\n",
        "    print(\"‚úÖ El modelo cumple el objetivo de F1 > 0.78\")\n",
        "    print(\"‚úÖ La extracci√≥n de informaci√≥n fue exitosa\")\n",
        "    print(\"‚úÖ El pipeline de limpieza funcion√≥ correctamente\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Considerar m√°s caracter√≠sticas o datos para mejorar rendimiento\")\n",
        "    print(\"‚ö†Ô∏è Evaluar t√©cnicas adicionales de NLP\")\n",
        "\n",
        "print(f\"\\nüéØ ESTADO DEL PROYECTO: {'EXITOSO' if best_score > 0.78 else 'REQUIERE MEJORAS'}\")\n",
        "print(\"üìÅ Todos los resultados est√°n disponibles en el objeto 'classifier'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === ALTERNATIVA: EJECUCI√ìN R√ÅPIDA CON UNA L√çNEA ===\n",
        "\n",
        "print(\"‚ö° OPCI√ìN R√ÅPIDA: Ejecutar todo el an√°lisis autom√°ticamente\")\n",
        "print(\"Descomenta la l√≠nea siguiente para ejecutar todo de una vez:\")\n",
        "\n",
        "# from modules import quick_start\n",
        "# analyzer, results = quick_start('ted_talks_en.csv')\n",
        "\n",
        "print(\"\\nüí° Esta opci√≥n ejecuta autom√°ticamente:\")\n",
        "print(\"  1. Configuraci√≥n del ambiente\")\n",
        "print(\"  2. Carga y limpieza de datos\") \n",
        "print(\"  3. Extracci√≥n de informaci√≥n NLP\")\n",
        "print(\"  4. Entrenamiento de modelos ML\")\n",
        "print(\"  5. Visualizaciones y m√©tricas\")\n",
        "print(\"  6. Conclusiones\")\n",
        "\n",
        "print(\"\\nüéØ Resultado esperado: F1-score > 0.78 en el mejor modelo\")\n",
        "print(\"üìä Todo optimizado para extracci√≥n de informaci√≥n de ted_talks_en.csv\")"
      ]
    }
  ],
  "metadata": {
    "deepnote_notebook_id": "9ef24892143a426ca3c75c3ddd0a2b31",
    "kernelspec": {
      "display_name": "cloudspace",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
