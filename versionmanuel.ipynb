{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Iniciando an√°lisis de TED Talks\n",
            "üìä Dataset: ted_talks_en.csv\n",
            "üéØ Objetivo: Extracci√≥n de informaci√≥n + Modelos ML\n",
            "OK - Sistema de progreso en tiempo real cargado\n",
            "Cargando m√≥dulos del proyecto TED Talks...\n",
            "‚úì M√≥dulo de configuraci√≥n del ambiente cargado\n",
            "OK - Sistema de progreso en tiempo real cargado\n",
            "Cargando m√≥dulos del proyecto TED Talks...\n",
            "‚úì M√≥dulo de configuraci√≥n del ambiente cargado\n",
            "‚úì M√≥dulo de limpieza de datos cargado\n",
            "‚úì M√≥dulo de limpieza de datos cargado\n",
            "‚úì M√≥dulo de procesamiento NLP cargado\n",
            "‚úì M√≥dulo de procesamiento NLP cargado\n",
            "‚úì M√≥dulo de visualizaci√≥n cargado\n",
            "‚úì M√≥dulo de machine learning cargado\n",
            "üéØ M√≥dulos TED Talks cargados correctamente\n",
            "üìö Uso recomendado:\n",
            "   from modules import quick_start\n",
            "   analyzer, results = quick_start('ted_talks_en.csv')\n",
            "==================================================\n",
            "‚úÖ M√≥dulos cargados correctamente\n",
            "‚úì M√≥dulo de visualizaci√≥n cargado\n",
            "‚úì M√≥dulo de machine learning cargado\n",
            "üéØ M√≥dulos TED Talks cargados correctamente\n",
            "üìö Uso recomendado:\n",
            "   from modules import quick_start\n",
            "   analyzer, results = quick_start('ted_talks_en.csv')\n",
            "==================================================\n",
            "‚úÖ M√≥dulos cargados correctamente\n"
          ]
        }
      ],
      "source": [
        "# === ANALISIS DE POPULARIDAD DE TED TALKS ===\n",
        "# Aplicacion de Extraccion de Informacion y Comparacion de Modelos ML\n",
        "\n",
        "print(\"Iniciando analisis de TED Talks\")\n",
        "print(\"Dataset: ted_talks_en.csv\")\n",
        "print(\"Objetivo: Extraccion de informacion + Modelos ML\")\n",
        "\n",
        "# Importar la clase principal que controla todo el flujo\n",
        "from modules import TedTalkAnalyzer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Modulos cargados correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ EJECUTANDO PRUEBA R√ÅPIDA DEL SISTEMA\n",
            "Esta celda verifica que todo est√© configurado correctamente\n",
            "=======================================================\n",
            "Iniciando: Iniciando verificaci√≥n r√°pida del sistema\n",
            "Tiempo de inicio: 04:29:58\n",
            "==================================================\n",
            "[1/4] (25.0%) Verificando imports b√°sicos... OK\n",
            "[04:29:58] Librer√≠as b√°sicas: OK\n",
            "[2/4] (50.0%) Verificando acceso a datos... OK\n",
            "[04:29:58] Librer√≠as b√°sicas: OK\n",
            "[2/4] (50.0%) Verificando acceso a datos... OK\n",
            " OK\n",
            "[04:29:59] Dataset cargado: 4,005 filas\n",
            "[3/4] (75.0%) Verificando m√≥dulos del proyecto...[04:29:59] Dataset cargado: 4,005 filas\n",
            "[3/4] (75.0%) Verificando m√≥dulos del proyecto... OK\n",
            "[04:29:59] M√≥dulos disponibles: 4/4\n",
            "[4/4] (100.0%) Verificando configuraci√≥n del ambiente... OK\n",
            "[04:29:59] M√≥dulos disponibles: 4/4\n",
            "[4/4] (100.0%) Verificando configuraci√≥n del ambiente... OK\n",
            "[04:29:59] TextBlob: OK\n",
            "\n",
            "==================================================\n",
            "Estado: Verificaci√≥n completada\n",
            "Tiempo total: 1.1 segundos\n",
            "Finalizado: 04:29:59\n",
            "Tiempo promedio por paso: 0.3s\n",
            "\n",
            "üéØ RESULTADO DE LA PRUEBA:\n",
            "========================================\n",
            "‚úÖ Librer√≠as b√°sicas: Funcionando\n",
            "‚úÖ Acceso a datos: OK\n",
            "‚úÖ M√≥dulos del proyecto: 4/4 disponibles\n",
            "üïê Verificaci√≥n completada: 04:29:59\n",
            "\n",
            "üí° Puedes proceder con el an√°lisis completo\n",
            "\n",
            "üöÄ ¬°Todo listo! Puedes continuar con el an√°lisis completo\n",
            "=======================================================\n",
            " OK\n",
            "[04:29:59] TextBlob: OK\n",
            "\n",
            "==================================================\n",
            "Estado: Verificaci√≥n completada\n",
            "Tiempo total: 1.1 segundos\n",
            "Finalizado: 04:29:59\n",
            "Tiempo promedio por paso: 0.3s\n",
            "\n",
            "üéØ RESULTADO DE LA PRUEBA:\n",
            "========================================\n",
            "‚úÖ Librer√≠as b√°sicas: Funcionando\n",
            "‚úÖ Acceso a datos: OK\n",
            "‚úÖ M√≥dulos del proyecto: 4/4 disponibles\n",
            "üïê Verificaci√≥n completada: 04:29:59\n",
            "\n",
            "üí° Puedes proceder con el an√°lisis completo\n",
            "\n",
            "üöÄ ¬°Todo listo! Puedes continuar con el an√°lisis completo\n",
            "=======================================================\n"
          ]
        }
      ],
      "source": [
        "# === CREAR INSTANCIA DEL ANALIZADOR ===\n",
        "\n",
        "print(\"Creando instancia del analizador TED Talks...\")\n",
        "\n",
        "# Crear instancia de la clase principal\n",
        "analyzer = TedTalkAnalyzer()\n",
        "\n",
        "print(\"Analizador creado correctamente\")\n",
        "print(\"Metodos disponibles:\")\n",
        "print(\"- setup_environment(): Configurar ambiente\")\n",
        "print(\"- load_data(): Cargar datos\")\n",
        "print(\"- clean_data(): Limpiar datos\")\n",
        "print(\"- process_nlp_features(): Procesar NLP\")\n",
        "print(\"- train_models(): Entrenar modelos ML\")\n",
        "print(\"- create_visualizations(): Crear graficos\")\n",
        "print(\"- run_complete_analysis(): Ejecutar todo automaticamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üïê INICIO: 04:29:59\n",
            "‚öôÔ∏è  Configurando ambiente y dependencias...\n",
            "üìä Esto puede tomar 2-5 minutos la primera vez\n",
            "==================================================\n",
            "=== CONFIGURACION DEL AMBIENTE ===\n",
            "Tiempo estimado: 2-5 minutos\n",
            "\n",
            "PASO 1/3: Instalando 8 paquetes esenciales...\n",
            "  [1/8] Instalando pandas>=1.3.0...Instalando pandas>=1.3.0... OK\n",
            "  [2/8] Instalando numpy>=1.21.0... OK\n",
            "  [2/8] Instalando numpy>=1.21.0... OK\n",
            "  [3/8] Instalando scikit-learn>=1.0.0... OK\n",
            "  [3/8] Instalando scikit-learn>=1.0.0... OK\n",
            "  [4/8] Instalando matplotlib>=3.4.0... OK\n",
            "  [4/8] Instalando matplotlib>=3.4.0... OK\n",
            "  [5/8] Instalando seaborn>=0.11.0... OK\n",
            "  [5/8] Instalando seaborn>=0.11.0... OK\n",
            "  [6/8] Instalando nltk>=3.7... OK\n",
            "  [6/8] Instalando nltk>=3.7... OK\n",
            "  [7/8] Instalando textblob>=0.17.0... OK\n",
            "  [7/8] Instalando textblob>=0.17.0... OK\n",
            "  [8/8] Instalando tqdm>=4.64.0... OK\n",
            "  [8/8] Instalando tqdm>=4.64.0... OK\n",
            "\n",
            "Paquetes esenciales: 8/8 instalados\n",
            "\n",
            "PASO 2/3: Instalando 3 paquetes opcionales...\n",
            "  [1/3] Instalando plotly>=5.0.0... OK\n",
            "\n",
            "Paquetes esenciales: 8/8 instalados\n",
            "\n",
            "PASO 2/3: Instalando 3 paquetes opcionales...\n",
            "  [1/3] Instalando plotly>=5.0.0... OK\n",
            "  [2/3] Instalando spacy>=3.4.0... OK\n",
            "  [2/3] Instalando spacy>=3.4.0... OK\n",
            "  [3/3] Instalando wordcloud>=1.8.0... OK\n",
            "  [3/3] Instalando wordcloud>=1.8.0... OK\n",
            "\n",
            "Paquetes opcionales: 3/3 instalados\n",
            "\n",
            "PASO 3/3: Configurando modelos de NLP...\n",
            "  Descargando datos NLTK... OK\n",
            "\n",
            "Paquetes opcionales: 3/3 instalados\n",
            "\n",
            "PASO 3/3: Configurando modelos de NLP...\n",
            "  Descargando datos NLTK... OK\n",
            "  Verificando spaCy... OK\n",
            "  Verificando spaCy... OK\n",
            "\n",
            "CONFIGURACION COMPLETADA\n",
            "========================================\n",
            "\n",
            "‚è±Ô∏è  Tiempo total: 25.3 segundos\n",
            "üïê COMPLETADO: 04:30:25\n",
            "==================================================\n",
            " OK\n",
            "\n",
            "CONFIGURACION COMPLETADA\n",
            "========================================\n",
            "\n",
            "‚è±Ô∏è  Tiempo total: 25.3 segundos\n",
            "üïê COMPLETADO: 04:30:25\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# === CONFIGURACION DEL AMBIENTE ===\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"INICIO:\", datetime.now().strftime(\"%H:%M:%S\"))\n",
        "print(\"Configurando ambiente y dependencias...\")\n",
        "print(\"Esto puede tomar 2-5 minutos la primera vez\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Configurar ambiente usando el metodo del analizador\n",
        "start_time = time.time()\n",
        "analyzer.setup_environment()\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed = end_time - start_time\n",
        "print(f\"\\nTiempo total: {elapsed:.1f} segundos\")\n",
        "print(f\"COMPLETADO:\", datetime.now().strftime(\"%H:%M:%S\"))\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Verificando que los m√≥dulos funcionan correctamente...\n",
            "  üìä pandas... ‚úÖ\n",
            "  üî¢ numpy... ‚úÖ\n",
            "  ü§ñ sklearn... ‚úÖ\n",
            "  üìà matplotlib... ‚úÖ\n",
            "  üî§ nltk... ‚úÖ\n",
            "  üéØ textblob... ‚úÖ\n",
            "\n",
            "‚úÖ Configuraci√≥n verificada - ¬°Todo listo para continuar!\n",
            "==================================================\n",
            " ‚úÖ\n",
            "  üî¢ numpy... ‚úÖ\n",
            "  ü§ñ sklearn... ‚úÖ\n",
            "  üìà matplotlib... ‚úÖ\n",
            "  üî§ nltk... ‚úÖ\n",
            "  üéØ textblob... ‚úÖ\n",
            "\n",
            "‚úÖ Configuraci√≥n verificada - ¬°Todo listo para continuar!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# === CARGA DE DATOS ===\n",
        "\n",
        "print(\"Cargando dataset ted_talks_en.csv...\")\n",
        "\n",
        "# Cargar datos usando el metodo del analizador\n",
        "analyzer.load_data('ted_talks_en.csv')\n",
        "\n",
        "# Mostrar informacion basica\n",
        "if analyzer.data_original is not None:\n",
        "    print(f\"Dataset cargado exitosamente\")\n",
        "    print(f\"Filas: {analyzer.data_original.shape[0]:,}\")\n",
        "    print(f\"Columnas: {analyzer.data_original.shape[1]}\")\n",
        "    print(f\"Memoria utilizada: {analyzer.data_original.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    \n",
        "    # Mostrar primeras columnas\n",
        "    print(\"\\nColumnas disponibles:\")\n",
        "    for i, col in enumerate(analyzer.data_original.columns):\n",
        "        print(f\"  {i+1}. {col}\")\n",
        "else:\n",
        "    print(\"ERROR: No se pudo cargar el dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === LIMPIEZA DE DATOS ===\n",
        "\n",
        "print(\"Aplicando limpieza profesional de datos...\")\n",
        "\n",
        "# Limpiar datos usando el metodo del analizador\n",
        "analyzer.clean_data()\n",
        "\n",
        "# Mostrar resultados de la limpieza\n",
        "if analyzer.data_clean is not None:\n",
        "    original_count = analyzer.data_original.shape[0]\n",
        "    clean_count = analyzer.data_clean.shape[0]\n",
        "    removed_count = original_count - clean_count\n",
        "    \n",
        "    print(f\"\\nResultados de la limpieza:\")\n",
        "    print(f\"  Filas originales: {original_count:,}\")\n",
        "    print(f\"  Filas despues de limpieza: {clean_count:,}\")\n",
        "    print(f\"  Filas eliminadas: {removed_count:,} ({removed_count/original_count*100:.1f}%)\")\n",
        "    \n",
        "    # Mostrar categorias de popularidad creadas\n",
        "    if 'popularity_category' in analyzer.data_clean.columns:\n",
        "        print(\"\\nCategorias de popularidad:\")\n",
        "        categories = analyzer.data_clean['popularity_category'].value_counts().sort_index()\n",
        "        for category, count in categories.items():\n",
        "            print(f\"  {category}: {count:,} videos\")\n",
        "            \n",
        "    # Mostrar calidad de datos\n",
        "    if 'data_cleaning' in analyzer.results:\n",
        "        quality_score = analyzer.results['data_cleaning']['quality_results']['quality_score']\n",
        "        print(f\"\\nPuntuacion de calidad de datos: {quality_score:.2f}/10\")\n",
        "else:\n",
        "    print(\"ERROR: No se pudo limpiar el dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === EXTRACCION DE INFORMACION CON NLP ===\n",
        "\n",
        "print(\"Aplicando tecnicas de extraccion de informacion...\")\n",
        "print(\"Procesando: sentimientos, entidades nombradas, caracteristicas textuales\")\n",
        "\n",
        "# Procesar caracteristicas NLP usando el metodo del analizador\n",
        "analyzer.process_nlp_features(text_column='transcript_clean')\n",
        "\n",
        "# Mostrar caracteristicas extraidas\n",
        "if analyzer.data_processed is not None:\n",
        "    print(f\"\\nExtraccion de informacion completada\")\n",
        "    print(f\"Dataset procesado: {analyzer.data_processed.shape}\")\n",
        "    \n",
        "    # Identificar caracteristicas NLP creadas\n",
        "    nlp_features = [col for col in analyzer.data_processed.columns if \n",
        "                   col.startswith(('sentiment_', 'text_', 'person_', 'org_', 'gpe_'))]\n",
        "    \n",
        "    print(f\"\\nCaracteristicas NLP extraidas: {len(nlp_features)}\")\n",
        "    print(\"Tipos de informacion extraida:\")\n",
        "    \n",
        "    # Agrupar por tipo\n",
        "    sentiment_features = [f for f in nlp_features if f.startswith('sentiment_')]\n",
        "    text_features = [f for f in nlp_features if f.startswith('text_')]\n",
        "    entity_features = [f for f in nlp_features if f.startswith(('person_', 'org_', 'gpe_'))]\n",
        "    \n",
        "    if sentiment_features:\n",
        "        print(f\"  Analisis de sentimientos: {len(sentiment_features)} caracteristicas\")\n",
        "    if text_features:\n",
        "        print(f\"  Caracteristicas textuales: {len(text_features)} caracteristicas\") \n",
        "    if entity_features:\n",
        "        print(f\"  Entidades nombradas: {len(entity_features)} caracteristicas\")\n",
        "        \n",
        "    # Mostrar estadisticas de muestra procesada\n",
        "    if 'nlp_processing' in analyzer.results:\n",
        "        sample_size = analyzer.results['nlp_processing']['sample_size']\n",
        "        print(f\"\\nMuestra procesada: {sample_size} registros\")\n",
        "else:\n",
        "    print(\"ERROR: No se pudo procesar las caracteristicas NLP\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-03T07:03:25.803244Z",
          "start_time": "2025-08-03T07:03:25.143615Z"
        },
        "cell_id": "5abe3fcf07e4410ea49ff1de3fca1b50",
        "deepnote_cell_type": "code",
        "execution_context_id": "d6f386e3-c5a2-41fb-85f0-dac17a4ccd4f",
        "execution_millis": 95512,
        "execution_start": 1754262986754,
        "source_hash": "ecbd79b7"
      },
      "outputs": [],
      "source": [
        "# === ENTRENAMIENTO Y COMPARACION DE MODELOS ML ===\n",
        "\n",
        "print(\"Entrenando y comparando modelos de Machine Learning...\")\n",
        "print(\"Objetivo: F1-score > 0.78\")\n",
        "\n",
        "# Entrenar modelos usando el metodo del analizador\n",
        "analyzer.train_models(text_column='transcript_clean', target_column='popularity_numeric')\n",
        "\n",
        "# Mostrar resultados de los modelos\n",
        "if 'machine_learning' in analyzer.results:\n",
        "    ml_results = analyzer.results['machine_learning']['model_results']\n",
        "    classifier = analyzer.results['machine_learning']['classifier']\n",
        "    \n",
        "    print(\"\\nRESULTADOS DE MODELOS:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Mostrar resultados de cada modelo\n",
        "    for model_name, results in ml_results.items():\n",
        "        if results is not None:\n",
        "            print(f\"\\n{model_name}:\")\n",
        "            print(f\"  Accuracy:  {results['accuracy']:.4f}\")\n",
        "            print(f\"  Precision: {results['precision']:.4f}\")\n",
        "            print(f\"  Recall:    {results['recall']:.4f}\")\n",
        "            print(f\"  F1-Score:  {results['f1_score']:.4f}\")\n",
        "            \n",
        "            # Verificar si cumple objetivo\n",
        "            objetivo_cumplido = \"SI\" if results['f1_score'] > 0.78 else \"NO\"\n",
        "            print(f\"  Objetivo F1>0.78: {objetivo_cumplido}\")\n",
        "    \n",
        "    # Identificar mejor modelo\n",
        "    best_model_name, best_model, best_score = classifier.get_best_model()\n",
        "    print(f\"\\nMEJOR MODELO: {best_model_name}\")\n",
        "    print(f\"F1-Score: {best_score:.4f}\")\n",
        "    \n",
        "    if best_score > 0.78:\n",
        "        print(\"Objetivo cumplido! F1-Score > 0.78\")\n",
        "    else:\n",
        "        print(\"Objetivo no cumplido. Considerar mas datos o mejores caracteristicas.\")\n",
        "        \n",
        "    # Guardar el mejor modelo para referencia\n",
        "    analyzer.best_model_name = best_model_name\n",
        "    analyzer.best_f1_score = best_score\n",
        "else:\n",
        "    print(\"ERROR: No se pudieron entrenar los modelos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-02T20:23:05.092879Z",
          "start_time": "2025-08-02T20:23:05.090755Z"
        },
        "cell_id": "e311e55f07eb4774aef2d27d4ba3f105",
        "deepnote_cell_type": "code",
        "execution_context_id": "d6f386e3-c5a2-41fb-85f0-dac17a4ccd4f",
        "execution_millis": 5768,
        "execution_start": 1754263082313,
        "source_hash": "f325302b"
      },
      "outputs": [],
      "source": [
        "# === METRICAS DE RENDIMIENTO Y VISUALIZACIONES ===\n",
        "\n",
        "print(\"Generando metricas de rendimiento y visualizaciones...\")\n",
        "\n",
        "# Crear visualizaciones usando el metodo del analizador\n",
        "analyzer.create_visualizations()\n",
        "\n",
        "# Mostrar informacion sobre las visualizaciones creadas\n",
        "if 'visualizations' in analyzer.results:\n",
        "    print(\"\\nVisualizaciones creadas exitosamente:\")\n",
        "    \n",
        "    # Si hay un clasificador disponible, mostrar importancia de caracteristicas\n",
        "    if hasattr(analyzer, 'best_model_name') and 'machine_learning' in analyzer.results:\n",
        "        classifier = analyzer.results['machine_learning']['classifier']\n",
        "        \n",
        "        print(f\"\\nImportancia de caracteristicas del mejor modelo ({analyzer.best_model_name}):\")\n",
        "        try:\n",
        "            feature_importance = classifier.get_feature_importance(analyzer.best_model_name, top_n=10)\n",
        "            for i, (feature, importance) in enumerate(feature_importance, 1):\n",
        "                print(f\"  {i:2d}. {feature}: {importance:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  No se pudo obtener importancia de caracteristicas: {e}\")\n",
        "    \n",
        "    print(\"\\nTipos de visualizaciones disponibles:\")\n",
        "    print(\"  - Distribucion de datos\")\n",
        "    print(\"  - Correlaciones entre variables\")\n",
        "    print(\"  - Metricas de modelos ML\")\n",
        "    print(\"  - Matrices de confusion\")\n",
        "    print(\"  - Comparacion de rendimiento\")\n",
        "else:\n",
        "    print(\"ERROR: No se pudieron crear las visualizaciones\")\n",
        "\n",
        "print(\"\\nAnalisis completo finalizado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "ba14dbd4adcd427685627c07bc45b6ec",
        "deepnote_cell_type": "code",
        "execution_context_id": "d6f386e3-c5a2-41fb-85f0-dac17a4ccd4f",
        "execution_millis": 578,
        "execution_start": 1754263088133,
        "source_hash": "8f5ea635"
      },
      "outputs": [],
      "source": [
        "# === RESUMEN FINAL Y CONCLUSIONES ===\n",
        "\n",
        "print(\"RESUMEN FINAL DEL ANALISIS:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Usar el metodo de resumen final del analizador\n",
        "analyzer.print_final_summary()\n",
        "\n",
        "# Informacion adicional sobre el estado del proyecto\n",
        "print(\"\\nESTADO DEL PROYECTO:\")\n",
        "if hasattr(analyzer, 'best_f1_score'):\n",
        "    if analyzer.best_f1_score > 0.78:\n",
        "        print(\"EXITOSO - Objetivo de F1 > 0.78 cumplido\")\n",
        "    else:\n",
        "        print(\"REQUIERE MEJORAS - Objetivo no cumplido\")\n",
        "        print(\"Recomendaciones:\")\n",
        "        print(\"  - Aumentar tamano de la muestra\")\n",
        "        print(\"  - Agregar mas caracteristicas NLP\")\n",
        "        print(\"  - Probar diferentes algoritmos\")\n",
        "        print(\"  - Mejorar limpieza de datos\")\n",
        "else:\n",
        "    print(\"INCOMPLETO - No se entrenaron modelos\")\n",
        "\n",
        "print(\"\\nACCESO A RESULTADOS:\")\n",
        "print(\"- analyzer.data_original: Dataset original\")\n",
        "print(\"- analyzer.data_clean: Dataset limpio\")\n",
        "print(\"- analyzer.data_processed: Dataset con caracteristicas NLP\")\n",
        "print(\"- analyzer.results: Diccionario con todos los resultados\")\n",
        "\n",
        "# Mostrar tamanos de datos procesados\n",
        "if analyzer.data_original is not None:\n",
        "    print(f\"\\nTAMANOS DE DATOS:\")\n",
        "    print(f\"  Original: {analyzer.data_original.shape}\")\n",
        "if analyzer.data_clean is not None:\n",
        "    print(f\"  Limpio: {analyzer.data_clean.shape}\")\n",
        "if analyzer.data_processed is not None:\n",
        "    print(f\"  Procesado: {analyzer.data_processed.shape}\")\n",
        "\n",
        "print(\"\\nANALISIS COMPLETADO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === OPCION: EJECUCION AUTOMATICA COMPLETA ===\n",
        "\n",
        "print(\"OPCION ALTERNATIVA: Ejecutar todo el analisis automaticamente\")\n",
        "print(\"Esta opcion ejecuta todos los pasos en una sola celda\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Descomenta las siguientes lineas para ejecutar todo automaticamente:\n",
        "\n",
        "# print(\"Iniciando analisis automatico...\")\n",
        "# analyzer_auto = TedTalkAnalyzer()\n",
        "# results = analyzer_auto.run_complete_analysis('ted_talks_en.csv')\n",
        "# print(\"Analisis automatico completado\")\n",
        "\n",
        "print(\"\\nEsta opcion automatica ejecuta:\")\n",
        "print(\"  1. Configuracion del ambiente\")\n",
        "print(\"  2. Carga de datos\") \n",
        "print(\"  3. Limpieza de datos\")\n",
        "print(\"  4. Extraccion de informacion NLP\")\n",
        "print(\"  5. Entrenamiento de modelos ML\")\n",
        "print(\"  6. Creacion de visualizaciones\")\n",
        "print(\"  7. Resumen final\")\n",
        "\n",
        "print(\"\\nResultado esperado: F1-score > 0.78 en el mejor modelo\")\n",
        "print(\"Tiempo estimado: 5-10 minutos\")\n",
        "print(\"Dataset optimizado para extraccion de informacion de ted_talks_en.csv\")\n",
        "\n",
        "print(\"\\nPara usar esta opcion:\")\n",
        "print(\"1. Descomenta las lineas 7-10\")\n",
        "print(\"2. Ejecuta esta celda\")\n",
        "print(\"3. Los resultados estaran en 'analyzer_auto' y 'results'\")"
      ]
    }
  ],
  "metadata": {
    "deepnote_notebook_id": "9ef24892143a426ca3c75c3ddd0a2b31",
    "kernelspec": {
      "display_name": "cloudspace",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
